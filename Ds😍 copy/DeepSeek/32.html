<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.min.js"></script>

<video id="video" autoplay playsinline style="display:none;"></video>
<canvas id="output" width="640" height="480"></canvas>
<div id="three-container" style="position: absolute; top: 0; left: 0;"></div>

<script>
  const videoElement = document.getElementById('video');
  const canvasElement = document.getElementById('output');
  const canvasCtx = canvasElement.getContext('2d');

  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(75, 640 / 480, 0.1, 1000);
  camera.position.z = 1;

  const renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setSize(640, 480);
  document.getElementById('three-container').appendChild(renderer.domElement);

  // Add silly glasses to face
  const glassesGroup = new THREE.Group();
  const torusGeometry = new THREE.TorusGeometry(0.05, 0.01, 16, 100);
  const material = new THREE.MeshBasicMaterial({ color: 0xffff00 });
  const leftEye = new THREE.Mesh(torusGeometry, material);
  const rightEye = new THREE.Mesh(torusGeometry, material);
  glassesGroup.add(leftEye);
  glassesGroup.add(rightEye);
  scene.add(glassesGroup);

  function updateGlasses(landmarks) {
    const left = landmarks[33];  // left eye
    const right = landmarks[263]; // right eye
    const nose = landmarks[1];

    leftEye.position.set((left.x - 0.5), -(left.y - 0.5), -left.z);
    rightEye.position.set((right.x - 0.5), -(right.y - 0.5), -right.z);
  }

  function animate() {
    requestAnimationFrame(animate);
    renderer.render(scene, camera);
  }
  animate();

  const faceMesh = new FaceMesh.FaceMesh({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
  });

  faceMesh.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5,
  });

  faceMesh.onResults((results) => {
    if (results.multiFaceLandmarks.length > 0) {
      updateGlasses(results.multiFaceLandmarks[0]);
    }
  });

  const cameraFeed = new Camera(videoElement, {
    onFrame: async () => {
      await faceMesh.send({ image: videoElement });
    },
    width: 640,
    height: 480,
  });
  cameraFeed.start();
</script>

<!--ðŸ”¥ Day 26: AR Face Filters (WebXR + Three.js)
ðŸ“Œ Hook: "AR face filters with JavaScript - no app needed! ðŸ¤³ #WebXR #AugmentedReality"-->

