<div>
  <video id="pose-video" width="300" autoplay muted></video>
  <canvas id="pose-canvas" width="300" height="300"></canvas>
</div>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.6"></script>
<script>
  (async () => {
    const video = document.getElementById('pose-video');
    const canvas = document.getElementById('pose-canvas');
    const ctx = canvas.getContext('2d');
    
    // Setup camera
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
    
    // Load PoseNet model
    const detector = await poseDetection.createDetector(
      poseDetection.SupportedModels.MoveNet,
      { modelType: poseDetection.movenet.modelType.SINGLEPOSE_THUNDER }
    );
    
    async function detectPose() {
      const poses = await detector.estimatePoses(video);
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      if (poses.length > 0) {
        drawSkeleton(poses[0].keypoints);
      }
      requestAnimationFrame(detectPose);
    }
    
    function drawSkeleton(keypoints) {
      ctx.fillStyle = 'red';
      ctx.strokeStyle = 'white';
      ctx.lineWidth = 2;
      
      // Draw keypoints
      keypoints.forEach(kp => {
        if (kp.score > 0.3) {
          ctx.beginPath();
          ctx.arc(kp.x, kp.y, 5, 0, 2 * Math.PI);
          ctx.fill();
        }
      });
      
      // Draw skeleton
      const connectedParts = [
        ['left_shoulder', 'right_shoulder'], ['left_shoulder', 'left_elbow'],
        ['left_elbow', 'left_wrist'], ['right_shoulder', 'right_elbow'],
        ['right_elbow', 'right_wrist'], ['left_shoulder', 'left_hip'],
        ['right_shoulder', 'right_hip'], ['left_hip', 'right_hip'],
        ['left_hip', 'left_knee'], ['left_knee', 'left_ankle'],
        ['right_hip', 'right_knee'], ['right_knee', 'right_ankle']
      ];
      
      connectedParts.forEach(([part1, part2]) => {
        const kp1 = keypoints.find(kp => kp.name === part1);
        const kp2 = keypoints.find(kp => kp.name === part2);
        
        if (kp1?.score > 0.3 && kp2?.score > 0.3) {
          ctx.beginPath();
          ctx.moveTo(kp1.x, kp1.y);
          ctx.lineTo(kp2.x, kp2.y);
          ctx.stroke();
        }
      });
    }
    
    detectPose();
  })();
</script>
<!--ðŸ”¥ Day 22: Machine Learning Pose Detection (TensorFlow.js + PoseNet)
ðŸ“Œ Hook: "Real-time pose detection in the browser - no backend needed! ðŸ’ƒ #TensorFlowJS #AI"-->





